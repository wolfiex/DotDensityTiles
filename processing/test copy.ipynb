{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from p_tqdm import p_map,p_umap,p_uimap,p_imap\n",
    "\n",
    "\n",
    "import glob, re , os \n",
    "import numpy as np\n",
    "dloc = '2021-oa-data'\n",
    "oloc = '../static/'\n",
    "tloc = 'temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of points \n",
    "# total = pd.read_csv(dloc+'/usual-residents-oa.csv').Count.sum()\n",
    "# total\n",
    "# waterways \n",
    "# water = gpd.read_file('inland-water.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom =  gpd.read_file('Output_Areas_(Dec_2021)_Boundaries_Full_Clipped_EW_(BFC).geojson').set_index('OA21CD')\n",
    "geom = geom.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def generate_random(number, polygon):\n",
    "    points = []\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    while len(points) < number:\n",
    "        pnt = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "        if polygon.contains(pnt):\n",
    "            points.append(pnt)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makepoints(area_chunks):\n",
    "    '''\n",
    "    This functions processes the points for several areas'''\n",
    "    dummy = []\n",
    "\n",
    "    for area in area_chunks:\n",
    "        row = data.loc[area]\n",
    "\n",
    "        for col in selection:\n",
    "            pts = generate_random(int(row[col]), geom.loc[area])\n",
    "            #need a format we can turn into geojson\n",
    "            dummy.extend([[area,col,p] for p in pts])\n",
    "\n",
    "    return dummy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = 'TS021_ethnic_group_tb_6a_2021'\n",
    "\n",
    "data = pd.read_csv(dloc+'/'+type+'.csv').set_index('Geography code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = list(data.columns).index('Classification') + 1\n",
    "end = list(data.columns).index('Total')\n",
    "selection = list(data.columns)[start:end]\n",
    "selection\n",
    "\n",
    "data = data[selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188880, 232183, 0.813496250802169)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# london = open('south.txt').read().split(',')\n",
    "london = list(set(data.index) & set(geom.index))\n",
    "len(london), len(data), len(london)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [29:55<00:00,  3.90it/s]  \n"
     ]
    }
   ],
   "source": [
    "allpoints = []\n",
    "nit = 7000\n",
    "ncores = 8\n",
    "\n",
    "allpoints = []\n",
    "# ratio optimised for macbook pro 8c 32gb\n",
    "for res in p_uimap(makepoints,np.array_split(london,nit),num_cpus=ncores):\n",
    "    allpoints.extend(res)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('temp.pickle', 'wb') as handle:\n",
    "    pickle.dump(allpoints, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('temp.pickle', 'rb') as handle:\n",
    "#     allpoints = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielellis/opt/miniconda3/envs/DataServer/lib/python3.9/site-packages/geopandas/io/file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gpd.GeoDataFrame(allpoints[:3],columns='cd cat geometry'.split()).to_file('sample.geojson', driver=\"GeoJSON\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50041 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "f = open(tloc + type + '.geojson','w')\n",
    "\n",
    "\n",
    "\n",
    "f.write('''{\n",
    "\"type\": \"FeatureCollection\",\n",
    "\"features\": [\n",
    "''')\n",
    "\n",
    "\n",
    "\n",
    "def linewise(segment):\n",
    "    fstr = ''\n",
    "    for x in segment:\n",
    "        p = x[2].xy\n",
    "        fstr+= '''{ \"type\": \"Feature\", \"properties\": { \"cd\": \"%s\", \"cat\": \"%s\" }, \"geometry\": { \"type\": \"Point\", \"coordinates\": [ %0.6f, %0.6f ] } },\\n'''%(x[0],x[1],p[0][0],p[1][0])\n",
    "    return fstr\n",
    "\n",
    "g = len(allpoints)//50000\n",
    "split = [allpoints[i:i+g]for i in range(0,len(allpoints),g) ]\n",
    "\n",
    "\n",
    "for res in p_uimap(linewise, split, num_cpus=ncores):\n",
    "    f.write(res)\n",
    "\n",
    "f.write('{  }\\n]}')\n",
    "\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allpoints)//50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595.98449\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def save_gj(x):\n",
    "#     fn, dummy = x\n",
    "#     pgdf = gpd.GeoDataFrame(dummy,columns='cd cat geometry'.split())\n",
    "#     geo = tloc + type + '_%02d.geojson'%fn\n",
    "#     # files.append(geo)\n",
    "#     pgdf.to_file(geo, driver=\"GeoJSON\")  \n",
    "#     return geo\n",
    "\n",
    "\n",
    "# os.system(f'rm {tloc}*.geojson')\n",
    "# p_umap(save_gj, enumerate(np.array_split(allpoints,10)),num_cpus=ncores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "temp/TS021_ethnic_group_tb_6a_2021.geojson:3: Found ] at top level\n",
      "temp/TS021_ethnic_group_tb_6a_2021.geojson:4: Reached EOF without all containers being closed\n",
      "In JSON object {\"type\":\"FeatureCollection\",\"features\":[]}\n",
      "10 features, 150 bytes of geometry, 16 bytes of separate metadata, 296 bytes of string pool\n",
      "Choosing a maxzoom of -z11 for features typically 442 feet (135 meters) apart, and at least 51 feet (16 meters) apart\n",
      "  99.5%  11/1016/650  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use parallel! as newline delimited geojson\n",
    "'-z16 -Bg'\n",
    "os.system(f'rm -rf {oloc}/{type}')\n",
    "os.system(f'/usr/local/bin/tippecanoe -f -l {type} -r3 --drop-fraction-as-needed --no-tile-compression --no-tile-size-limit --no-feature-limit -P --output-to-directory=\"{oloc}/{type}\" -zg -B12 -Z9 {tloc}*')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st='' \n",
    "key = '`'\n",
    "for i,s in enumerate(selection):\n",
    "    st+= f'\"{s}\" , colour[{i}],'\n",
    "    key+=\"<span style='color:${colour[%d]}'> %s </span><br>\"%(i,s)\n",
    "st+='\"#ccc\"'\n",
    "key+='`'\n",
    "\n",
    "print(st)\n",
    "print()\n",
    "print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DataServer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9da6e78936f6a8ab907bad03d2fac666a6d46a2192eea18a6af8d3db83b62898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
